# -*- coding: utf-8 -*-
"""fashion mnist dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W4h_Ui4HcO4g8pRSEqhsgGAAUNmO3ieg
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense,Flatten

(xtrain,ytrain),(xtest,ytest) = keras.datasets.fashion_mnist.load_data()

xtrain[0].shape

xtrain[0]

import matplotlib.pyplot as plt
plt.imshow(xtrain[0])

xtest[0]

ytest

plt.imshow(xtest[0])

#scaling
xtrain = xtrain/255
xtest = xtest/255

xtrain.shape

ytrain

from keras.api._v2.keras import activations
#model building
mod = Sequential()

mod.add(Flatten(input_shape=(28,28)))

mod.add(Dense(32,activation = 'relu'))
mod.add(Dense(16,activation = 'relu'))

mod.add(Dense(10,activation = 'softmax'))  # multi class classification reason

# because multi class classification loss is sparse catagorical crossentropy
mod.compile(loss = 'sparse_categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])

history = mod.fit(xtrain,ytrain,epochs=25,validation_split=0.2)

xtest[0]

yprob=mod.predict(xtest)
yprob[0]

ypred=yprob.argmax(axis=1)
ypred

from sklearn.metrics import classification_report
print(classification_report(ytest,ypred))

plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])

